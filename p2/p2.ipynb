{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FHXzk2t9rzW"
      },
      "source": [
        "# <center>**Práctica 2: Trabajo de Investigación**</center>\n",
        "## <center>Procesamiento de Imagen, Vídeo y Audio</center>\n",
        "### <center>Grado en Ciencia e Ingeniería de Datos</center>\n",
        "### <center>Curso 2022/2023</center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J88EBnff-Ivh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Y2FtEl9rzZ"
      },
      "outputs": [],
      "source": [
        "import skimage.io as io\n",
        "import scipy as sp\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfH2P2px9rza"
      },
      "source": [
        "Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxMuC3e49rza"
      },
      "source": [
        "Igual si hay tiempo es buena idea ponerlo como prueba también  \n",
        "\n",
        "balancear imagenes 50% negro 50% blanco - para que detecte las carreteras\n",
        "quitar pixeles negros para tener 50-50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAkfQkh49rzb"
      },
      "source": [
        "mascara como y \n",
        "rgb como data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxjOYjRU9rzb"
      },
      "source": [
        "### **1. Ejercicio 1: Segmentación de carreteras en imagen aérea de alta resolución**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwA4HiEw9rzb"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos de la carpeta data \n",
        "data = io.imread_collection('/content/drive/MyDrive/piva-p2/data/roads/sat/*.tiff')\n",
        "labels = io.imread_collection('/content/drive/MyDrive/piva-p2/data/roads/gt/*.tif')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEJOR HACER UN BASELINE MAS SENCILLO, Y MAS ADELANTE COMPARAR MODELOS Y ASI DECIDIR QUE NOS QUEDAMOS CON LA U-NET"
      ],
      "metadata": {
        "id": "Kaks8_I0SfF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utilizar np.split para obtener train, val y test\n",
        "X_train, X_val, X_test = np.split(data, [int(.7*len(data)), int(.9*len(data))])\n",
        "y_train, y_val, y_test = np.split(labels, [int(.7*len(labels)), int(.9*len(labels))])\n",
        "\n",
        "y_train = np.expand_dims(y_train, axis=3)\n",
        "y_val = np.expand_dims(y_val, axis=3)\n",
        "y_test = np.expand_dims(y_test, axis=3)"
      ],
      "metadata": {
        "id": "9NDMH49W9lOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hacemos un baseline autoencoder para ver que tal se comporta\n",
        "def baseline(input_shape):\n",
        "    # encoder\n",
        "    input_img = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # decoder\n",
        "    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "seJxNh1I9fJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = baseline([1500,1500,3])\n",
        "baseline.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()]) #['accuracy', 'mse', 'mae', 'mape'])"
      ],
      "metadata": {
        "id": "nzpwygMg9nVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.fit(X_train, y_train, epochs=5, batch_size=1, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "nGTzmgiE9za1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline.evaluate(X_test, y_test)\n",
        "\n",
        "predictions = baseline.predict(X_test)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(y_test[0], cmap='gray')\n",
        "ax1.set_title('GT image')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(predictions[0], cmap='gray')\n",
        "ax2.set_title('Predicted image')\n",
        "ax2.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TcgeHtcs-CFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-NET"
      ],
      "metadata": {
        "id": "IcWu1ejfQqrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, Concatenate, BatchNormalization, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    batch1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(3,3))(batch1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    batch2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2,2))(batch2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    batch3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2,2))(batch3)  \n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    batch4 = BatchNormalization()(conv4)\n",
        "\n",
        "    # Decoder\n",
        "    convtrans1 = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(batch4)\n",
        "    merge1 = Concatenate(axis=3)([convtrans1, batch4])\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge1)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up1 = UpSampling2D(size=(2,2))(conv5)\n",
        "    convtrans2 = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "    merge2 = Concatenate(axis=3)([convtrans2, batch3])\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge2)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up2 = UpSampling2D(size=(2,2))(conv6)\n",
        "    convtrans3 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "    merge3 = Concatenate(axis=3)([convtrans3, batch2])\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge3)\n",
        "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up3 = UpSampling2D(size=(3,3))(conv7)\n",
        "    convtrans4 = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(up3)\n",
        "    merge4 = Concatenate(axis=3)([convtrans4, batch1])\n",
        "\n",
        "    # Output\n",
        "    outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(merge4)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9su4mmczIMKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U_net = unet((1500, 1500, 3))\n",
        "U_net.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()]) #['accuracy', 'mse', 'mae', 'mape'])"
      ],
      "metadata": {
        "id": "QDWHI0raOArl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U_net.fit(X_train, y_train, epochs=5, batch_size=1, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "0Qt3P3K2Onhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos\n",
        "U_net.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "TLYrcaDPEcYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = U_net.predict(X_test)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(y_test[0], cmap='gray')\n",
        "ax1.set_title('GT image')\n",
        "ax1.axis('off')\n",
        "ax2.imshow(predictions[0], cmap='gray')\n",
        "ax2.set_title('Predicted image')\n",
        "ax2.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cDLEBlBhEmy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1tgWHVr9rze"
      },
      "source": [
        "#### Preprocesado de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEQZqja29rze"
      },
      "outputs": [],
      "source": [
        "from skimage import exposure\n",
        "\n",
        "# Normalización de imágenes\n",
        "norm_data = []\n",
        "for img in data:\n",
        "    norm_img = exposure.equalize_adapthist(img, clip_limit=0.03) # Normaliza la imagen usando la corrección de contraste adaptativo\n",
        "    norm_data.append(norm_img)\n",
        "\n",
        "# Visualización de una imagen normalizada\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(data[0])\n",
        "ax1.set_title('Imagen original')\n",
        "ax2.imshow(norm_data[0])\n",
        "ax2.set_title('Imagen normalizada')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmSNoWzK9rze"
      },
      "outputs": [],
      "source": [
        "from skimage.filters import gaussian, median\n",
        "\n",
        "# Eliminación de ruido \n",
        "smooth_data = []\n",
        "for img in norm_data:\n",
        "    smooth_img = gaussian(img, sigma=1) # Filtro Gaussiano con sigma=1\n",
        "    smooth_img = median(smooth_img) # Filtro de mediana con tamaño de ventana predeterminado\n",
        "    smooth_data.append(smooth_img)\n",
        "\n",
        "# Visualización de una imagen suavizada\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(norm_data[0])\n",
        "ax1.set_title('Imagen normalizada')\n",
        "ax2.imshow(smooth_data[0])\n",
        "ax2.set_title('Imagen suavizada')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OfgWeID9rzf"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "# Ajuste de la resolución de las imágenes\n",
        "resized_data = []\n",
        "for i in range(len(smooth_data)):\n",
        "    resized_img = resize(smooth_data[i], (512, 512), anti_aliasing=True)\n",
        "    resized_data.append(resized_img)\n",
        "\n",
        "# Visualización de una imagen redimensionada\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(smooth_data[0])\n",
        "ax1.set_title('Imagen suavizada')\n",
        "ax2.imshow(resized_data[0])\n",
        "ax2.set_title('Imagen redimensionada')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIL0b_BR9rzg"
      },
      "source": [
        "#### Extracción de características"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2GUnX0M9rzg"
      },
      "outputs": [],
      "source": [
        "# Segmentación de color de las imágenes\n",
        "from skimage.color import rgb2hsv\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "segmented_data = []\n",
        "for img in resized_data:\n",
        "    hsv_img = rgb2hsv(img)\n",
        "    v = hsv_img[:, :, 2]\n",
        "    thresh = threshold_otsu(v)\n",
        "    binary = v > thresh\n",
        "    segmented_data.append(binary)\n",
        "\n",
        "# Visualización de una imagen segmentada\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(resized_data[0])\n",
        "ax1.set_title('Imagen redimensionada')\n",
        "ax2.imshow(segmented_data[0])\n",
        "ax2.set_title('Imagen segmentada')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9wLmqIp9rzg"
      },
      "outputs": [],
      "source": [
        "# convertimos resized_data a grayscale\n",
        "gray_resized_data = [np.dot(img[...,:3], [0.299, 0.587, 0.114]) for img in resized_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7kzecqB9rzg"
      },
      "outputs": [],
      "source": [
        "from skimage import feature\n",
        "\n",
        "# Detección de bordes utilizando el operador Canny\n",
        "# convertir resized_data a escala de grises\n",
        "edges = []\n",
        "for i in range(len(gray_resized_data)):\n",
        "    edge = feature.canny(gray_resized_data[i], sigma=4, low_threshold=0.05, high_threshold=0.2)\n",
        "    edges.append(edge)\n",
        "\n",
        "# Visualización de la imagen original y los bordes detectados\n",
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.imshow(gray_resized_data[2], cmap='gray')\n",
        "ax1.set_title('Imagen original')\n",
        "ax2.imshow(edges[2], cmap='gray')\n",
        "ax2.set_title('Bordes detectados')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n58_ZoR9rzh"
      },
      "source": [
        "#### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mitw8Am_9rzh"
      },
      "outputs": [],
      "source": [
        "input_img = Input(shape=(512, 512, 1))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = np.split(edges, [int(.7*len(data)), int(.9*len(data))])\n",
        "# y_train, y_val, y_test = np.split(labels, [int(.7*len(labels)), int(.9*len(labels))])\n",
        "\n",
        "# y_train = np.expand_dims(y_train, axis=3)\n",
        "# y_val = np.expand_dims(y_val, axis=3)\n",
        "# y_test = np.expand_dims(y_test, axis=3)"
      ],
      "metadata": {
        "id": "yG2geSLVZs1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "78u-pHCMIwhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(512, 512, 3))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "batch1 = BatchNormalization()(conv1)\n",
        "maxpool1 = MaxPooling2D(pool_size=(3,3))(batch1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(maxpool1)\n",
        "batch2 = BatchNormalization()(conv2)\n",
        "maxpool2 = MaxPooling2D(pool_size=(2,2))(batch2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(maxpool2)\n",
        "batch3 = BatchNormalization()(conv3)\n",
        "maxpool3 = MaxPooling2D(pool_size=(2,2))(batch3)    \n",
        "\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(maxpool3)\n",
        "batch4 = BatchNormalization()(conv4)\n",
        "\n",
        "convT1 = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(batch4)\n",
        "concat1 = Concatenate(axis=3)([convT1, batch4])\n",
        "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat1)\n",
        "\n",
        "upsam1 = UpSampling2D(size=(2,2))(conv5)\n",
        "convT2 = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(upsam1)\n",
        "concat2 = Concatenate(axis=3)([convT2, batch3])\n",
        "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
        "\n",
        "upsam2 = UpSampling2D(size=(2,2))(conv6)\n",
        "convT3 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(upsam2)\n",
        "concat3 = Concatenate(axis=3)([convT3, batch2])\n",
        "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(concat3)\n",
        "\n",
        "upsam3 = UpSampling2D(size=(3,3))(conv7)\n",
        "convT4 = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(upsam3)\n",
        "concat4 = Concatenate(axis=3)([convT4, batch1])\n",
        "conv8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(concat4)\n",
        "\n",
        "unet = Model(input_img, conv8)\n",
        "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()]) #['accuracy', 'mse', 'mae', 'mape'])\n"
      ],
      "metadata": {
        "id": "t-c4mgMEIkqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4O8_i9f9rzh"
      },
      "outputs": [],
      "source": [
        "unet.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d7546de2d5b66e6bb4051f93f462cf1f21acc5c70ac66712f7c9fa60f386dd80"
      }
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}